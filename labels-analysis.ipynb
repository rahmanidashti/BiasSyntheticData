{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LLM Judgment - Human Judgment as a Target\n",
    "\n",
    "This experiments applied the signed differecnes of LLM labels and human labels as a target for analysis the features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qrels = glob.glob(f'./qrels/*.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qrels_df_list = []\n",
    "\n",
    "for infile in qrels:\n",
    "    judger = infile.split('/')[2].split('.')[3]\n",
    "    result_df = pd.read_csv(infile, sep=' ', header=None, names=['qid', 'Q0', 'docid', 'score'])\n",
    "    result_df.drop(['Q0'], axis=1, inplace=True)\n",
    "    result_df['judged_by'] = judger\n",
    "    result_df['qid'] = result_df['qid'].astype(int)\n",
    "    result_df['score'] = result_df['score'].astype(int)\n",
    "    qrels_df_list.append(result_df)\n",
    " \n",
    "qrels_df = pd.concat(qrels_df_list)\n",
    "qrels_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qid_to_info = pd.read_csv(\"infos/query_to_info.txt\", sep='\\t')\n",
    "qrels_df = pd.merge(qrels_df, qid_to_info, on='qid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qrels_df['judged_by'] = qrels_df['judged_by'].replace({'withDupes': 'Human', 'gpt4': 'GPT-4'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add a new column called 'QT' and the values are \"Real\" if Synthetic is 0 and isGPT is 0, \"T5\" if Synthetic is 1 and isGPT is 0, \n",
    "# \"GPT-4\" if Synthetic is 0 and isGPT is 1\n",
    "qrels_df['QT'] = np.where((qrels_df['Synthetic'] == 0) & (qrels_df['isGPT4'] == 0), 'Real',\n",
    "                          np.where((qrels_df['Synthetic'] == 1) & (qrels_df['isGPT4'] == 0), 'T5', 'GPT-4'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = qrels_df[['score', 'judged_by', 'QW', 'QT']]\n",
    "df['score'] = df['score'].astype('category')\n",
    "\n",
    "sns.set_style(\"ticks\")  # Options: white, dark, whitegrid, darkgrid, ticks\n",
    "sns.set_context(\"poster\", font_scale =0.8)     # Options: paper, notebook, talk, poster\n",
    "sns.set_palette(\"bright\")   # You can also use: deep, muted, bright, dark, colorblind, or a custom list of colors\n",
    "\n",
    "# Create a FacetGrid for the label type\n",
    "g = sns.FacetGrid(df, col=\"QT\", hue=\"judged_by\", height=5)\n",
    "\n",
    "# Add a histogram to the FacetGrid\n",
    "g.map(sns.histplot, 'score', stat=\"proportion\", hue = 'judged_by', multiple='dodge', shrink = .8, common_norm=False, data = df)\n",
    "\n",
    "# Adjust the titles and labels\n",
    "g.add_legend()\n",
    "g.set_axis_labels(\"\", \"Proportion\", fontsize=22)\n",
    "g.set_titles(col_template=\"{col_name}\", fontsize=22)\n",
    "\n",
    "titles = ['Labels for Human Queries', 'Labels for T5 Queries', 'Labels for GPT-4 Queries']\n",
    "\n",
    "for ax, title in zip(g.axes.flatten(), titles):\n",
    "    ax.set_title(title)\n",
    "    \n",
    "sns.move_legend(g, ncol=3, loc='upper center', title = '')\n",
    "\n",
    "# Adjust layout\n",
    "plt.subplots_adjust(top=0.8)\n",
    "# plt.legend(fontsize=19, ncol=2, loc='upper center')\n",
    "# Show the plot\n",
    "plt.xticks([0, 1, 2, 3])  # Set y-ticks to 0, 1, 2, 3\n",
    "plt.savefig(\"figs/label_barplots.pdf\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
