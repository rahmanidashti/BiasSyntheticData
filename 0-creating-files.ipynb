{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import tarfile\n",
    "import json\n",
    "import gzip\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "nist_qrel_file = 'qrels/2023.qrels.pass.withDupes.txt'\n",
    "gpt4_qrel_file = 'qrels/2023.qrels.pass.gpt4.txt'\n",
    "dl_2023_queries = \"dl-2023-queries.tsv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading judged queries\n",
    "nist_qrels = pd.read_csv(nist_qrel_file, sep=' ', header=None, names=['qid', 'Q0', 'docid', 'rel'])\n",
    "queries_judged = set(nist_qrels['qid'])\n",
    "\n",
    "# no. of relevant/irrelevant doc per query\n",
    "# Group by qid and score, then count the occurrences\n",
    "nist_qrels_counts = nist_qrels.groupby(['qid', 'rel']).size().reset_index(name='count')\n",
    "\n",
    "# Pivot the dataframe to get counts for each score\n",
    "pivot_df = nist_qrels_counts.pivot(index='qid', columns='rel', values='count').fillna(0)\n",
    "\n",
    "# Calculate the sum of relevant scores (1, 2, 3) and the count of non-relevant scores (0)\n",
    "pivot_df['relevant_count'] = pivot_df[1] + pivot_df[2] + pivot_df[3]\n",
    "pivot_df['non_relevant_count'] = pivot_df[0]\n",
    "\n",
    "# Calculate the average number of relevant scores divided by the count of non-relevant scores\n",
    "pivot_df['average_relevant'] = pivot_df['relevant_count'] / pivot_df['non_relevant_count']\n",
    "\n",
    "# Select only the necessary columns\n",
    "nist_qrels_avg = pivot_df[['relevant_count', 'non_relevant_count', 'average_relevant']].reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_to_info = pd.read_csv(\"infos/doc_to_info.txt\", sep='\\t')\n",
    "nist_qrels_with_docinfo = pd.merge(nist_qrels, doc_to_info, on='docid')\n",
    "# Group by 'GroupColumn' and calculate the mean and count of 'ValueColumn'\n",
    "qid_to_MeanDocLength = nist_qrels_with_docinfo.groupby('qid')['DW'].agg('mean').to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading judged queries - GPT-4\n",
    "gpt4_qrels = pd.read_csv(gpt4_qrel_file, sep=' ', header=None, names=['qid', 'Q0', 'docid', 'rel'])\n",
    "\n",
    "# no. of relevant/irrelevant doc per query\n",
    "# Group by qid and score, then count the occurrences\n",
    "gpt4_qrels_counts = gpt4_qrels.groupby(['qid', 'rel']).size().reset_index(name='count')\n",
    "\n",
    "# Pivot the dataframe to get counts for each score\n",
    "pivot_df = gpt4_qrels_counts.pivot(index='qid', columns='rel', values='count').fillna(0)\n",
    "\n",
    "# Calculate the sum of relevant scores (1, 2, 3) and the count of non-relevant scores (0)\n",
    "pivot_df['relevant_count'] = pivot_df[1] + pivot_df[2] + pivot_df[3]\n",
    "pivot_df['non_relevant_count'] = pivot_df[0]\n",
    "\n",
    "# Calculate the average number of relevant scores divided by the count of non-relevant scores\n",
    "pivot_df['average_relevant'] = pivot_df['relevant_count'] / pivot_df['non_relevant_count']\n",
    "\n",
    "# Select only the necessary columns\n",
    "gpt4_qrels_avg = pivot_df[['relevant_count', 'non_relevant_count', 'average_relevant']].reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "qid_to_avgrelevant_nist = dict(zip(nist_qrels_avg.qid, nist_qrels_avg.average_relevant))\n",
    "qid_to_avgrelevant_gpt4 = dict(zip(gpt4_qrels_avg.qid, gpt4_qrels_avg.average_relevant))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qid</th>\n",
       "      <th>qtext</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2000138</td>\n",
       "      <td>How does the process of digestion and metaboli...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2000438</td>\n",
       "      <td>apatite definition</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2000727</td>\n",
       "      <td>calculate salary from basic pay</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2000882</td>\n",
       "      <td>cerebellar disease definition</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2001010</td>\n",
       "      <td>cost comparison of funerals in australia</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       qid                                              qtext\n",
       "0  2000138  How does the process of digestion and metaboli...\n",
       "1  2000438                                 apatite definition\n",
       "2  2000727                    calculate salary from basic pay\n",
       "3  2000882                      cerebellar disease definition\n",
       "4  2001010           cost comparison of funerals in australia"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "queries = pd.read_csv(dl_2023_queries, sep='\\t', header=None, names=['qid', 'qtext'])\n",
    "queries.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_query_length(query_text):\n",
    "    query_len = len(query_text.split(' '))\n",
    "    if query_len >= 10:\n",
    "        # long query == 1\n",
    "        query_len_type = 1\n",
    "    else:\n",
    "        # short query == 0\n",
    "        query_len_type = 0\n",
    "    return query_len_type, query_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"query_to_info.txt\", 'w') as q2i:\n",
    "    q2i.write(\"qid\\tQL\\tQDR\\tQDS\\tQW\\tDL\\tSynthetic\\tisGPT4\\n\")\n",
    "    for eachquery in queries.itertuples(index=True):\n",
    "        if eachquery.qid in queries_judged:\n",
    "            qid_len_type, qid_len = get_query_length(eachquery.qtext)\n",
    "            qid_avgrel_real = round(qid_to_avgrelevant_nist[eachquery.qid], 4)\n",
    "            qid_avgrel_gpt4 = round(qid_to_avgrelevant_gpt4[eachquery.qid], 4)\n",
    "            doc_len = round(qid_to_MeanDocLength[eachquery.qid], 4)\n",
    "            if eachquery.qid < 3000000:\n",
    "                qid_synthetic = 0\n",
    "            else:\n",
    "                qid_synthetic = 1\n",
    "            if eachquery.qid < 3100000:\n",
    "                qid_isGPT4 = 0\n",
    "            else:\n",
    "                qid_isGPT4 = 1\n",
    "            q2i.write(f\"{eachquery.qid}\\t{qid_len_type}\\t{qid_avgrel_real}\\t{qid_avgrel_gpt4}\\t{qid_len}\\t{doc_len}\\t{qid_synthetic}\\t{qid_isGPT4}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Documents/Passages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docids = set(nist_qrels['docid'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_bundles(bundlenum):\n",
    "     with gzip.open(f'msmarco_v2_passage/msmarco_passage_{bundlenum}.gz','r') as fpassage:\n",
    "          for passage in fpassage:\n",
    "            json_passage = json.loads(passage.decode('utf8'))\n",
    "            if json_passage['pid'] in docids:\n",
    "                docid_to_passage[json_passage['pid']] = json_passage['passage']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read TREC passagess\n",
    "docid_to_passage = {}\n",
    "\n",
    "for bundlenum in tqdm(range(0, 70)):\n",
    "    if bundlenum < 10:\n",
    "        bundlenum = f'0{str(bundlenum)}'\n",
    "    read_bundles(bundlenum=bundlenum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_doc_length(passage):\n",
    "    passage_len = len(passage.split(' '))\n",
    "    return passage_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"doc_to_info.txt\", 'w') as d2i:\n",
    "    d2i.write(\"docid\\tDW\\n\")\n",
    "    for eachline in nist_qrels.itertuples(index=True):\n",
    "        doc_len = get_doc_length(docid_to_passage[eachline.docid])\n",
    "        d2i.write(f\"{eachline.docid}\\t{doc_len}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
